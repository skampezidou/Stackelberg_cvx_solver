# 1 model for all 76 customers
# Data from UC Davis

import numpy as np
import custom_fun, os
import visualization
import pandas

def find_files(path, extension):
    files = [x for x in os.listdir(path) if x.endswith(extension)]
    return files
#current_path = os.getcwd()
#data_files = find_files(current_path+'/Data/', '.csv')

# General
T = 24#24
a = 2
rounds = 10#150
epochs = 500
learn_rate = 0.9
delta_learn_rate = 0.01
threshold = 0.1
thres_term = 0.01
# Supply function parameters: b = 7.95*0.00001, c = -82.38*0.00001

# Q percentage range, u range
min_Q_perc = 0.02#0.001#0.02 #Q is at least 2% of total daily nom_load
max_Q_perc = 0.1#0.009#0.1
min_u = 0.0003#2
max_u = 0.0004#5
K = 100#1500#15 #basis dimension for learning

# May 29, 2020 data UCDavis
prices = [0.02576471,0.02388076,0.02191809,0.01962237,0.01984479,0.02509045,0.02499305,0.02255181,0.01684952,0.01703261,0.01843098,0.02396503,0.02598486,0.0307526,0.03409971,0.04265038,0.0479632,0.0595037,0.0732513,0.11047397,0.07157856,0.04664244,0.03269036,0.02894639]
nom_loads, nom_total = custom_fun.read_large_data(os.getcwd()+'/Data_May_29/'+'total.csv')

#prices = [0.5*x for x in prices]

# Choose subset of data
nom_loads, nom_total, prices = custom_fun.subdata_selection(nom_loads, nom_total, prices, T)


#Player's choices
u_pros = np.random.uniform(min_u,max_u,len(nom_loads))# =[0.0003123447116076854, 0.00046760178056920573]
Q_pros = [np.random.uniform(min_Q_perc,max_Q_perc)*np.sum(x) for x in nom_loads] #[233.55711750417595, 21.039598997919647]
p_max = min(prices) #5*max(prices)

u_pros = u_pros.tolist()


# Initialize model
batch_size = T
A_basis = np.random.random((K-1, T))
c_basis = np.random.random((K-1,))
P0 = 1000*np.identity(K, dtype = float)
Th0 = np.random.random((K,T))
m = 1

p_all = []
ga_est_all = []
ga_true_all = []
ga_est = []
x_tot_est_all = []
pros_all = []
d_all = [] # sum_x_round_j, vector in T
test = []
nans = []

Th_j_1 = Th0
P_j_1 = P0
P_all = []

nom_all = []
denom_all = []
ga_tilde_all = []

for k in range(0,2):
    if k == 0:
        learn_rate = 0.9
        filename = 'Output_EE_RLS/pros_with_expl.csv'
    else:
        learn_rate = 0
        filename = 'Output_EE_RLS/pros_wo_expl.csv'

    p_all = []
    ga_est_all = []
    ga_true_all = []
    ga_est = []
    x_tot_est_all = []
    pros_all = []
    d_all = []  # sum_x_round_j, vector in T
    test = []
    nans = []
    Th_j_1 = Th0
    P_j_1 = P0
    P_all = []
    nom_all = []
    denom_all = []
    ga_tilde_all = []

    for i in range(0, rounds):
        print('Iteration:', i)

        temp_eig_P = np.linalg.eigvals(P_j_1)
        P_all.append(temp_eig_P.tolist())

        p0 = np.random.uniform(0, p_max, T)
        p0 = np.reshape(p0, (p0.shape[0],1))
        res_agg = custom_fun.agg_est_opt_RLS(p0, Th_j_1, prices, nom_total, A_basis, c_basis, p_max, T)

        p_random = np.random.uniform(0, p_max, T) #100 for T=2/K=15   #(0, p_max, T)
        p_star = learn_rate * p_random + (1-learn_rate) * res_agg.x


        round_i_pros = []
        for j in range(0, len(nom_loads)):
            round_i_pros.append(custom_fun.pros_opt_RLS(nom_loads[j], p_star, a, u_pros[j], Q_pros[j], T))
        pros_all.append(round_i_pros)


        temp_list = []
        for k in range(0, len(round_i_pros)):
            temp_list.append(round_i_pros[k][1])


        temp_array = np.asarray(temp_list)
        temp_array_tr = np.transpose(temp_array)
        list_temp = temp_array_tr.tolist()
        d_temp = [np.sum(x) for x in list_temp]
        d_all.append(d_temp)

        ga_true_new = custom_fun.agg_true_obj_RLS(p_star, d_temp, nom_total, prices)

        # Get estimate of d_tilde with RLS
        d_tilde = custom_fun.RLS_predict(Th_j_1, A_basis, c_basis, p_star)
        x_tot_est_all.append(d_tilde.flatten().tolist()) #d_tilde

        ##
        ga_tilde = custom_fun.agg_temp_obj_RLS(p_star, d_tilde, nom_total, prices)
        ga_tilde_all.append(ga_tilde)
        ##

        p_all.append(p_star)
        ga_est.append(res_agg.fun)
        ga_true_all.append(ga_true_new)

        # Update Theta in RLS
        Th_j, P_j, epsilon_j, nominator, denominator = custom_fun.update_RLS(p_star, Th_j_1, A_basis, c_basis, d_temp, m, P_j_1)
        Th_j_1 = Th_j
        P_j_1 = P_j
        nom_all.append(nominator)
        denom_all.append(denominator)


        if np.linalg.norm([np.abs([x-y]) for x,y in zip(d_all[-1], d_tilde)]) < threshold:
            learn_rate = 0
            print('rate 0')
            test.append(i)

        if np.linalg.norm([np.abs([x-y]) for x,y in zip(d_all[-1], d_tilde)]) < thres_term:
            break

        pros_lower_viol = []
        for l in range(0, len(nom_loads)):
            pros_lower_viol.append([1 for i in round_i_pros[l][1] if i < 0])

        print("Violations of prosumer's lower bound: ", pros_lower_viol)

        print("Learning rate: ", learn_rate)
        print('---------------------------------------------------')

        if learn_rate > 0:
            learn_rate = learn_rate - delta_learn_rate
        elif learn_rate < 0.02:
            learn_rate = 0
        else:
            learn_rate = 0

    # Plot
    visualization.plot_error_RLS(d_all, x_tot_est_all)
    visualization.plot_obj_RLS(ga_true_all, ga_est, ga_tilde_all, pros_all, rounds, nom_loads)
    visualization.plot_actions_RLS(d_all, x_tot_est_all, a, nom_total)
    visualization.plot_agg_actions_RLS(p_all, p_max, prices, rounds)
    custom_fun.output_data(filename, nom_loads, Q_pros, pros_all)


print(np.sum(Q_pros))

df = pandas.DataFrame()
df['prices'] = prices
df['p'] = p_all[-1]
df['nom_total'] = nom_total
df['d_tilde'] = x_tot_est_all[-1]
df.to_csv('Output_EE_RLS/trial.csv')